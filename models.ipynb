{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZewhI9Gjv_AR"
   },
   "source": [
    "### Modelagem:\n",
    "\n",
    "* taxa_crime_k_regiao_i = caracteristica_j_usr_regiao_i\n",
    "\n",
    "* taxa_crime_k_regiao_i: ideal que seja uma média anual 5 anos\n",
    "\n",
    "* taxa_crime_k_regiao_i = a*caracteristica_0_usr_regiao_i + b*caracteristica_1_usr_regiao_i + c*caracteristica_2_usr_regiao_i + d*caracteristica_3_usr_regiao_i + e*caracteristica_4_usr_regiao_i + f*caracteristica_5_usr_regiao_i\n",
    "\n",
    "# Características de usuários na região\n",
    "- Média valores dos usuários na região\n",
    "\n",
    "* Características do usuário\n",
    " * 0 perfil-protegido: {0,1}\n",
    " * 1 qtd_seguidores_ano: número real  (qtd_seguidores/anos_conta)\n",
    " * 2 qtd_seguindo_ano: número real\n",
    " * 3 qtd_tweets_ano: número real\n",
    " * 4 anos_conta: número inteiro\n",
    " * 5 perfil-verificado: {0,1}\n",
    "\n",
    "### Metodologia de avaliação: one-leaves-out\n",
    "\n",
    "* para cada região i,\n",
    "    remover a linha i das caracteristicas\n",
    "    treinar o modelo\n",
    "    registrar o erro para i (matriz de erros: linha i colunas MAE, RAE, R2)\n",
    "\n",
    "* Calcular Média de MAE, RAE, R2 para tipo de crime k\n",
    "\n",
    "1. agrupamento\n",
    "2. corrigir o Y soma(maio/22-abr/23)\n",
    "3. desempenho com 82-regiões e 78-regiões-gte_100usrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1434,
     "status": "ok",
     "timestamp": 1686663096659,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "H32F7yUjdE5d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(np.arange(1,54))\n",
    "l2 = [56,57,58,62,63,64,65,66,69,70,73,75,77,78,80,81,85,87,89,90,91,92,96,97,98,99,101,102,103]\n",
    "areas = l1+l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1686580347009,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "qDCYaIE4AlU7",
    "outputId": "bb9bb68f-0077-4471-a56c-a4e8058aa41e"
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"Datasets/dataset_features_users_POIs.csv\")\n",
    "# targets = targets.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\", \"qtd_users\"])\n",
    "features = features.drop(columns=[\"Unnamed: 0\"])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv(\"Datasets/dataset_soma_ocorr_2022.csv\")\n",
    "\n",
    "# targets = targets.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\", \"qtd_users\"])\n",
    "targets = targets.drop(columns=[\"Unnamed: 0\"])\n",
    "# targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[\"area\"] = areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets[[\"area\",\"total_homicidios\", \"total_estupro\", \"total_les_corporal\", \"total_roubo2\", \"total_furt\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDothR1xsh4C",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Random Forest (POIs + Caractrísticas de Usuários)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 115602,
     "status": "ok",
     "timestamp": 1686666062285,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "HLSmsRQqtFe_"
   },
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória como 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# separar as features\n",
    "X = features.values\n",
    "\n",
    "#normaliza\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# criar um objeto do modelo Random Forest Regressor\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# criar um objeto LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "importances = pd.DataFrame()\n",
    "erros = pd.DataFrame()\n",
    "#matriz de metricas RAE, MAE e R2\n",
    "metricas = pd.DataFrame(columns=['Ocorrencia','RAE','MAE','R2'])\n",
    "ocorrencias = []\n",
    "media_rae = []\n",
    "media_mae =[]\n",
    "media_r2 = []\n",
    "\n",
    "for i in targets.columns:\n",
    "\n",
    "  list_y_test = []\n",
    "  list_y_pred = []\n",
    "  # separa a variável target\n",
    "  y = targets[i].values\n",
    "\n",
    "  # percorrer cada amostra do conjunto de dados\n",
    "  for train_index, test_index in loo.split(X):\n",
    "\n",
    "      # separar os conjuntos de treinamento e teste\n",
    "      X_train, X_test = X[train_index], X[test_index]\n",
    "      y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "      # treinar o modelo\n",
    "      model.fit(X_train, y_train)\n",
    "\n",
    "      #adiciona a importancia das features para predição da target i\n",
    "      importances[i] = model.feature_importances_\n",
    "\n",
    "      # fazer a previsão usando o conjunto de teste\n",
    "      y_pred = model.predict(X_test)\n",
    "\n",
    "      list_y_test.append(y_test[0])\n",
    "      list_y_pred.append(y_pred[0])\n",
    "\n",
    "  erros[i+\"_true\"] = list_y_test\n",
    "  erros[i+\"_pred\"] = list_y_pred\n",
    "  # calcular o erro relativo absoluto (RAE) e adiciona na lista\n",
    "  media_rae.append(mean_absolute_error(list_y_test, list_y_pred) / np.mean(list_y_test))\n",
    "  # calcular o erro absoluto medio (MAE) e adiciona na lista\n",
    "  media_mae.append(mean_absolute_error(list_y_test, list_y_pred))\n",
    "  # calcular R2 e adiciona na lista\n",
    "  media_r2.append(r2_score(list_y_test,list_y_pred))\n",
    "  #tipo de ocorrencia\n",
    "  ocorrencias.append(i)\n",
    "\n",
    "\n",
    "metricas[\"Ocorrencia\"] = ocorrencias\n",
    "metricas[\"RAE\"] = media_rae\n",
    "metricas[\"MAE\"] = media_mae\n",
    "metricas[\"R2\"] = media_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1686666081470,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "jmENTFKKIeo4",
    "outputId": "ca76164b-8904-4ecb-a2bc-d2adcc2a9e1e"
   },
   "outputs": [],
   "source": [
    "erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1686599532356,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "_ecRjIZJCPb1",
    "outputId": "09ce3abb-6de9-495e-9684-f2bf714462ff"
   },
   "outputs": [],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MeqG6CG6oLq",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SVM (POIs + Caractrísticas de Usuários)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1686673764563,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "b4S0V6pbGEAR"
   },
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória como 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# separar as features\n",
    "X = features.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# criar modelo SVM\n",
    "model = SVR(kernel='linear')\n",
    "\n",
    "# normalização min-max\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_minmax = scaler_minmax.fit_transform(X)\n",
    "# normalização z-score\n",
    "# scaler_zscore = StandardScaler()\n",
    "# X_zscore = scaler_zscore.fit_transform(X)\n",
    "\n",
    "# criar um objeto LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "#erros\n",
    "errosSVM = pd.DataFrame()\n",
    "\n",
    "#matriz de metricas RAE, MAE e R2\n",
    "metricas = pd.DataFrame(columns=['Ocorrencia','RAE','MAE','R2'])\n",
    "ocorrencias = []\n",
    "media_rae = []\n",
    "media_mae =[]\n",
    "media_r2 = []\n",
    "\n",
    "\n",
    "\n",
    "for i in targets.columns:\n",
    "\n",
    "  list_y_test = []\n",
    "  list_y_pred = []\n",
    "  # separa a variável target\n",
    "  y = targets[i].values\n",
    "\n",
    "\n",
    "  # percorrer cada amostra do conjunto de dados\n",
    "  for train_index, test_index in loo.split(X_minmax):\n",
    "\n",
    "      # separar os conjuntos de treinamento e teste\n",
    "      X_train, X_test = X[train_index], X[test_index]\n",
    "      y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "      # treinar o modelo\n",
    "      model.fit(X_train, y_train)\n",
    "\n",
    "      # fazer a previsão usando o conjunto de teste\n",
    "      y_pred = model.predict(X_test)\n",
    "\n",
    "      list_y_test.append(y_test[0])\n",
    "      list_y_pred.append(y_pred[0])\n",
    "\n",
    "      #print(\"index do teste\", test_index)\n",
    "      #print(\"index do treino\", train_index)\n",
    "  errosSVM[i+\"y_true\"] = list_y_test\n",
    "  errosSVM[i+\"y_pred\"] = list_y_pred\n",
    "  # # calcular o erro relativo absoluto (RAE) e adiciona na lista\n",
    "  media_rae.append(mean_absolute_error(list_y_test, list_y_pred) / np.mean(list_y_test))\n",
    "  # # calcular o erro absoluto medio (MAE) e adiciona na lista\n",
    "  media_mae.append(mean_absolute_error(list_y_test, list_y_pred))\n",
    "  # # calcular R2 e adiciona na lista\n",
    "  media_r2.append(r2_score(list_y_test,list_y_pred))\n",
    "  # #tipo de ocorrencia\n",
    "  ocorrencias.append(i)\n",
    "\n",
    "\n",
    "metricas[\"Ocorrencia\"] = ocorrencias\n",
    "metricas[\"RAE\"] = media_rae\n",
    "metricas[\"MAE\"] = media_mae\n",
    "metricas[\"R2\"] = media_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errosSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1686581554755,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "41s9WT7FJNvu",
    "outputId": "41be433b-8188-472b-e7b4-82b4eb4fc26b"
   },
   "outputs": [],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDgC31KuqnNy",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwu2mf8TtDhS"
   },
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória como 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# separar as features\n",
    "X = features.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# criar um objeto do modelo Random Forest Regressor\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# criar um objeto LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "#matriz de metricas RAE, MAE e R2\n",
    "metricas = pd.DataFrame(columns=['Ocorrencia','RAE','MAE','R2'])\n",
    "ocorrencias = []\n",
    "media_rae = []\n",
    "media_mae =[]\n",
    "media_r2 = []\n",
    "\n",
    "\n",
    "for i in targets.columns:\n",
    "  list_y_test = []\n",
    "  list_y_pred = []\n",
    "  # separa a variável target\n",
    "  y = targets[i].values\n",
    "\n",
    "\n",
    "  # percorrer cada amostra do conjunto de dados\n",
    "  for train_index, test_index in loo.split(X):\n",
    "\n",
    "      # separar os conjuntos de treinamento e teste\n",
    "      X_train, X_test = X[train_index], X[test_index]\n",
    "      y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "      # treinar o modelo\n",
    "      model.fit(X_train, y_train)\n",
    "\n",
    "      #adiciona a importancia das features para predição da target i\n",
    "      #importances[i] = model.feature_importances_\n",
    "\n",
    "      # fazer a previsão usando o conjunto de teste\n",
    "      y_pred = model.predict(X_test)\n",
    "\n",
    "      list_y_test.append(y_test)\n",
    "      list_y_pred.append(y_pred)\n",
    "\n",
    "\n",
    "  # calcular o erro relativo absoluto (RAE) e adiciona na lista\n",
    "  media_rae.append(mean_absolute_error(list_y_test, list_y_pred) / np.mean(list_y_test))\n",
    "  # calcular o erro absoluto medio (MAE) e adiciona na lista\n",
    "  media_mae.append(mean_absolute_error(list_y_test, list_y_pred))\n",
    "  # calcular R2 e adiciona na lista\n",
    "  media_r2.append(r2_score(list_y_test,list_y_pred))\n",
    "  #tipo de ocorrencia\n",
    "  ocorrencias.append(i)\n",
    "\n",
    "\n",
    "metricas[\"Ocorrencia\"] = ocorrencias\n",
    "metricas[\"RAE\"] = media_rae\n",
    "metricas[\"MAE\"] = media_mae\n",
    "metricas[\"R2\"] = media_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1686581754284,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "piKgP0bTtDhU",
    "outputId": "7ae1a331-ad72-450c-b97d-1f76accf9da4"
   },
   "outputs": [],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dBYAbMVvP19",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5ClK7u7vTnR"
   },
   "outputs": [],
   "source": [
    "# Definindo a semente aleatória como 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# separar as features\n",
    "X = features.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# criar um objeto do modelo Random Forest Regressor\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# criar um objeto LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "#matriz de metricas RAE, MAE e R2\n",
    "metricas = pd.DataFrame(columns=['Ocorrencia','RAE','MAE','R2'])\n",
    "ocorrencias = []\n",
    "media_rae = []\n",
    "media_mae =[]\n",
    "media_r2 = []\n",
    "\n",
    "\n",
    "for i in targets.columns:\n",
    "  list_y_test = []\n",
    "  list_y_pred = []\n",
    "  # separa a variável target\n",
    "  y = targets[i].values\n",
    "\n",
    "\n",
    "  # percorrer cada amostra do conjunto de dados\n",
    "  for train_index, test_index in loo.split(X):\n",
    "\n",
    "      # separar os conjuntos de treinamento e teste\n",
    "      X_train, X_test = X[train_index], X[test_index]\n",
    "      y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "      # treinar o modelo\n",
    "      model.fit(X_train, y_train)\n",
    "\n",
    "      #adiciona a importancia das features para predição da target i\n",
    "      #importances[i] = model.feature_importances_\n",
    "\n",
    "      # fazer a previsão usando o conjunto de teste\n",
    "      y_pred = model.predict(X_test)\n",
    "\n",
    "      list_y_test.append(y_test)\n",
    "      list_y_pred.append(y_pred)\n",
    "\n",
    "\n",
    "  # calcular o erro relativo absoluto (RAE) e adiciona na lista\n",
    "  media_rae.append(mean_absolute_error(list_y_test, list_y_pred) / np.mean(list_y_test))\n",
    "  # calcular o erro absoluto medio (MAE) e adiciona na lista\n",
    "  media_mae.append(mean_absolute_error(list_y_test, list_y_pred))\n",
    "  # calcular R2 e adiciona na lista\n",
    "  media_r2.append(r2_score(list_y_test,list_y_pred))\n",
    "  #tipo de ocorrencia\n",
    "  ocorrencias.append(i)\n",
    "\n",
    "\n",
    "metricas[\"Ocorrencia\"] = ocorrencias\n",
    "metricas[\"RAE\"] = media_rae\n",
    "metricas[\"MAE\"] = media_mae\n",
    "metricas[\"R2\"] = media_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1686581756659,
     "user": {
      "displayName": "Glauber Gonçalves",
      "userId": "03492418089079171948"
     },
     "user_tz": 180
    },
    "id": "Z1-ffXz4vWAF",
    "outputId": "25ccffe6-c66b-4c6d-9289-26b87f1037f6"
   },
   "outputs": [],
   "source": [
    "metricas"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOktEInh0F4ay2S9/cu3GAF",
   "collapsed_sections": [
    "RxHMfZ3-pESc",
    "xM0mhIcnMPQi",
    "rDkXd_PVMVyI",
    "9MeqG6CG6oLq",
    "iMrv_HBNUpjq",
    "jDgC31KuqnNy",
    "9TvaU3Zg7RN7",
    "6uQoVj1mFYT8",
    "s_ohlkurctAC",
    "V159BlnFcv0-",
    "ZCiRcJjIcyRc"
   ],
   "gpuType": "A100",
   "mount_file_id": "1P3FZK0fCq35ysIoyEyIi9MaKzRFkxXv-",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
